var documents = [

{
    "id": 0,
    "uri": "search.html",
    "menu": "-",
    "title": "Search",
    "text": " lokale Suche https://codersblock.com/blog/mini-previews-for-links/ div#searchresults h3 { font-size: larger; margin-top: 0 !important; } div#searchresults h4 { font-size: large; } div#searchresults span { font-size: small; } div#searchresults span.menu { font-size: medium; margin-top: 1em; } function dosearch(element) { if (element.value.length>=3) { var searchresults = document.querySelector('#searchresults'); out = \"\"; var results = idx.search(element.value); if (results.length == 0) { results = idx.search(element.value+\"*\"); } if (results.length == 0) { results = idx.search(\"*\"+element.value+\"*\"); } if (results.length == 0) { results = idx.search(element.value+\"~1\"); } var lastMenu = \"\" var lastTitle = \"\" results.forEach(function (item) { var doc = documents[item.ref]; out += \" \"+doc.menu+\" \"; if (doc.menu != lastMenu) { lastMenu = doc.menu; } out += \" \" + doc.title + \" \"; for(var field in item.matchData.metadata) { console.log(field); var matches = item.matchData.metadata[field] if (matches['text']) { matches['text']['position'].forEach(function (pos) { var subtext = doc.text.substring(pos[0]-50,pos[0]+pos[1]+50); if (pos[0]>0) { subtext = subtext.replace(new RegExp(/^[^ ]*/,\"i\"),\"...\"); } subtext = subtext.replace(new RegExp(/[^ ]*$/,\"i\"),\"...\"); var re = new RegExp(field,\"gi\"); subtext = subtext.replace(re,\" $& \"); out += \" \" + subtext + \" \"; }) } } searchresults.innerHTML = out; }) } } var input = document.querySelector(\"#lunrsrc\"); input.focus(); var params = new URLSearchParams(window.location.search); input.value = params.get('q'); dosearch(input); "
},

{
    "id": 1,
    "uri": "blog/2023/2023-08-21-vue2-vue3-migration.html",
    "menu": "Blog",
    "title": "Migrate Vue 2 to Vue 3",
    "text": " Table of Contents How we migrated our Vue 2 enterprise project to Vue 3 About me and my Team Where we started Preparations Migrations before the migration Finally: Migrate to Vue 3 Post-Migration-Steps Conclusion How we migrated our Vue 2 enterprise project to Vue 3 It&#8217;s been a while: Since the 2nd February 2022, Vue 3 became the new default for Vue.js apps. It&#8217;s done! Vue 3 is now the default version and the brand new http://vuejs.org is live! More details in the blog post in case you missed it: https://blog.vuejs.org/posts/vue-3-as-the-new-default.html Tweet from @vuejs on Twitter It was a long journey to the final default release of Vue 3 since the first version published on 18th September 2020. But: even if Vue 3 isn&#8217;t a new thing anymore, there are still a lot of Vue 2 apps which haven&#8217;t been migrated yet. The migration can be quite heavy since in practice it&#8217;s much more than only following the migration guide. Projects usually rely also on 3rd-party dependencies which are maybe not available for Vue 3 or not maintained anymore. In this blog post I will give you an insight into how my team mastered the migration and what pitfalls we faced. I will describe how we planned and migrated our whole Vue 2 codebase to Vue 3 using Pinia as Store-Solution, Vite for our build environment and Vitest for fast unit test executions. The focus of this article is not to provide a very detailed step-by-step migration guide. I will focus about what things you should keep in mind, what you can already do before starting the migration and about some pitfalls we pointed out. However, I will provide you links to more detailed blog posts about specific topics. Please keep in mind, that the way we solved the migration won&#8217;t probably fit to your very specific setup for 100%, but you can check what parts seem to be good for you and your team. Vue 2 EOL: Please note, that the Vue 2 support will end on December 31st, 2023. This means there will be no fixes and features provided anymore (unless you are actively extending the support ) About me and my Team To give you a high level overview about our context, I would just like to say a few short words about myself and my team. I am working at DB Systel GmbH , in a DevOps Team building a Business-to-Government (B2G) solution together with our partner Deutsche Bahn Connect GmbH named DB Curbside Management . Our product focuses on helping cities and councils to effectively manage shared mobility offerings and their jurisdictions dynamically. They will be able to get insights about statistics, violations of agreements with the mobility providers to regulate a fair and steady distribution of all the different shared mobility vehicles across managed area. Where we started My team added the migration to Vue 3 with the new default setup and tools using Vite , Pinia and Vitest to our backlog many months ago, but the switch to Vue 3 as default gave us another push for facing the migration. We realized pretty fast, that a big-bang migration wouldn&#8217;t be possible for us, since it will block us releasing new features for quite a long time. Our codebase contained already ~200 Vue 2 components using the old-fashioned Options API as well as a huge Vuex Store and some libraries that aren&#8217;t compatible with Vue 3. Preparations Let&#8217;s start with the preparation of your team and questions you should answer yourself before starting the migration. The first thing you should do is to get comfy with Vue 3, and you should learn about the differences compared to Vue 2 and the options you have. You can set up a Vue 3 playground app locally and explore yourself the new setup and components. To know what things will change when starting the migration, I would recommend you the read the following articles in advance: Official Vue 2 to Vue 3 Migration Guide Blogpost: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin Official Vue 3 notes about the Composition API and the relationship / differences compared to the Options API Vue Master Blog-Series by Andy Li Part 1 | Part 2 Free Vue Mastery Video Course \"From Vue 2 to Vue 3\" Update to the latest minor Vue 2 version My first advice is to keep your current app as up-to-date as possible. Especially when your Vue version is below 2.7.x , I would recommend you to update it. With Vue 2.7.x \"Naruto\" release, the Vue team aimed to backport lots of features from Vue 3 to Vue 2 without introducing a breaking change. This will help you to migrate some things in preparation for a smooth Vue 3 switch. Check out the official announcement and start migrating to the Vue 3 flavour in your Vue 2 app: TypeScript or not? Are you using TypeScript right now or do you plan to migrate to TypeScript? In that case you should read the TypeScript Notes for Vue 3 . Generally I would highly recommend to use TypeScript as the Vue 2 and Vue 3 TypeScript integration is great. It will help you a lot to reduce runtime errors as hard debugging nights by analyzing bugs in production. Be prepared, that switching to Typescript might require quite an effort, but it&#8217;s still worth it. Check your dependencies A big thing you definitely have to check before is: dependencies. You should check if you are using packages that will rely on Vue 2 and won&#8217;t be available for Vue 3. Such dependencies will require your attention as they may block you from updating to Vue 3. In my previous project we weren&#8217;t able to update to Vue 3 a long time since we had a dependency to BootstrapVue which wasn&#8217;t working with Vue 3 and isn&#8217;t still. In such case where a package isn&#8217;t compatible you have the following options: Check if there is an equivalent package or a fork of your dependency that will support Vue 3. If there is one: be sure it&#8217;s still maintained and alive. If the package is just a Vue-wrapper for a common library, you may need to use the library directly Find a similar package that supports Vue 3. In this case you have to make sure the new dependency supports all your use-cases, and you have to plan how to migrate this dependency. You can contribute to the dependency and help to make it Vue 3 compatible. You may have to check VueDemi which is a great developing utility to create or update Universal Vue Libraries for Vue 2 &amp; 3. Worst Case: Write the features you need by yourself, but be sure to open-source it afterwards ;-) In all these cases you should make yourself a list of the relevant development tasks with a very rough estimate about how complex the migration will be. For example write a + if the dependency migration is straight forward (already Vue 3 compatible). Write + for very hard-to-migrate dependencies, where you may need another solution or lib or implement stuff by yourself. Add Notes about things you shouldn&#8217;t forget when starting the migration. You should also include development dependencies for example for webpack plugins. It could look like the following example: Vue 2 dependency Vue 3 dependency notes estimate @dsb-norge/vue-keycloak-js @baloise/vue-keycloak similar API, similar features ++ v-tooltip floating-vue same lib under the hood with more features + vue2-datepicker vue-datepicker-next same lib with Vue 3 support + vue2-leaflet @vue-leaflet/vue-leaflet same API, but lots of relying components ++ | vue2-leaflet-draw-toolbar | - | no Vue 3 equivalent | ++ | | webpack-license-plugin | rollup-plugin-license | different plugin for rollup, with a different API, we need to check / adjust the output format | | Try out things in a playground For dependency update / migrations you can&#8217;t estimate, it&#8217;s a good idea to set them up / try them out in an isolated new Vue 3 playground environment. After playing around, you should be able to estimate the effort. A good example when having a look at the migration list above would be to try out the rollup-plugin-license package. Check your current Webpack environment When coming from webpack and planning to migrate to Vite, you should check your webpack config for any special behaviors. You can use the playground to reflect / try out the setup in Vite. Here are some points that were interesting for us: We don&#8217;t need a specific SCSS/SASS/LESS configuration anymore as Vite brings support for this out-of-the-box We needed to migrate the webpack-license-plugin to rollup-plugin-license (see above) Vite comes with its own approach of reading and passing environment variables and build modes which is quite easy and handy Static Asset Handling by Vite is something you should probably know before Split your Store on paper When currently using Vuex, you may be lucky, and you have already some modules splitting your store into logical parts. In our case we had just one big store without any modules as the codebase has evolved over time, and we haven&#8217;t made the step to split the store. The migration to Pinia can be a good chance to face this now as Pinia lets you easily compose multiple small stores. You should check your current store configuration and write down the modules that are loosely coupled or even completely independent (e.g. a user or an auth store). Make the migration transparent and estimable The last thing we have done was to create a new epic for the whole migration and to create small estimable tasks. This was very important as we were now able to identify things we can prepare and do even before we started the migration itself and also tasks we can do in advance. On the other hand it helped us for the communication with the product owner and to make things transparent. Please keep in mind to add some time buffer for unexpected things occurring during the migration where you may need some extra time. For example: the migration from Vuex to Pinia took a lot more time than we thought before. But: it was definitely worth it. The TypeScript support is way better and the unification of actions and mutations reduces the Boilerplate code a lot. We also underestimated the time we needed to migrate the tests. This was hard by definition but quite time-consuming as I wrote in the introduction: We had a huge Vuex store. Migrations before the migration Before starting the migration itself you should migrate everything you can, which is not related to Vue 3 / vite. Here is what we have done in my team before the migration itself. Convert Filters to functions Vue 3 kicked out the concept of using filters in the template using the pipe ( | ) syntax ( {{ expression | myFilter }} ). Filters are simply functions that can be imported and used directly. You can already import the functions, use them as a method and then pass through the expression in the template before starting the Vu3 migration: {{ myFilter(expression) }} . Update and migrate dependencies Update all possible dependencies to their latest versions to make migrations for other libs in advance. At this step: double-check if vue-specific libs are ready for using with Vue 3 or if there are other libs you have to use. If you have to change to other libs and this one supports Vue 3, make the migration now. In our team we had already lots of our dependencies updated, since we are using Mend (formerly Whitesource) Renovate for housekeeping and continuous dependency version updates. When you decide to migrate a dependency to a new one that supports Vue 2 and Vue 3 or which should be replaced with a self-implementation: Do it in advance before the actual Vue migration. Isolate hard-to-migrate components It may happens, you realize, for some of your dependencies a migration won&#8217;t be straight-forward. In our case we decided some years ago, we want to use Leaflet.js as our map library to display and interact with features on a map. Therefore we also used a wrapper for Vue 2 applications called Vue2Leaflet which made us use Leaflet in a declarative manner. However, this architectural decision was now a problem for us, as not only this dependency is not supposed to use it with Vue 3 but also extensions for this library such as Leaflet.heat needed to be migrated. To face this issue we&#8217;ve gone one step back and rethink our architectural decision to use Leaflet. At this time there was already a Vue 3 wrapper for leaflet available but not as feature-rich as we needed it. So we created a new Architectural Decision Record (ADR) to evaluate and choose our future map library as it is a central component of our app and can&#8217;t be easily replaced. After doing a Proof-of-Concept (PoC), we decided to switch to OpenLayers and make use of the vue3-openlayers wrapper too, where we were also able to contribute missing features back into the project. This whole story is probably quite special to my team and our app, but the essential thing here was, that we prepared the central components in parallel to our productive app in a separate repository in isolation. Therefore, we created the components and defined their props and events with the help of Storybook . Of course, we also created tests for these components, so that we were prepared to copy over all this into the productive app and replace the existing components later, when we were ready to actually migrate to Vue 3. A drawback with this approach is of course: It probably blocks you with releasing new features or you have to implement them twice during the preparation time (one time for the productive app based on Vue 2, one time for the isolated components based on Vue 3). Update your NPM Scripts When checking your Vue 3 default setup you will notice that some NPM script names have changed by default. For example the default command to run the development build and server is now npm run dev instead of npm run serve . You can either change the names back since you are used to the \"old\" commands, or you can already name your commands in the Vue 2 setup to the new ones to get comfy with it. Please note that you may have to change the commands in you CI/CD Pipeline too. Switch to Vite You can switch to Vite before updating to Vue 3 this makes the \"big bang\" migration a bit smaller. For that, you should install Vite and use the official plugin @vitejs/plugin-vue2 . You also need to migrate all the webpack plugins and configs. When the setup is finished, cleanup all the webpack stuff including the config and the dependencies. During the migration we noticed, that we haven&#8217;t used Type-Only Imports in all our typescript and .vue files. The default Vite setup is configured in such way, Type-Only Imports will be forced when needed, otherwise you&#8217;ll receive errors during the build. We had the option to either deactivate this strict behavior by setting the typescript config option importsNotUsedAsValues to either preserve or remove (not recommended) or to migrate. Luckily, there is a community project called ts-import-types-cli that will automate a part of this step. So we just had to run the following command to migrate to Type-Only Imports at places needed: # remove the `--dry-run` flag to migrate actually and not only list the changes npx ts-import-types-cli --no-organise-imports -p tsconfig.json --dry-run The bad news: The tool didn&#8217;t find all occurrences of the Type-Only Imports, so when running npm run build , we caught some more we had to fix manually. Switch to Vitest After your migration to Vite, you should make use of Vitest as your new pretty and fast unit testing framework. In comparison to Jest it comes with a stable out-of-the-box ESM support and faster test executions. Until now Jest&#8217;s support for ESM is still experimental (State: Jest Version 29.5). The API is quite similar and mostly compatible to jest . If you used Mocha before, the migration shouldn&#8217;t be hard either. Switch to Pinia The next big step you should do in advance is the migration of your Vuex store. You can also do this step after the migration itself and keep Vuex for now. However, we decided, it&#8217;s a good idea, to migrate the store before and switch to Pinia since the API is a lot simpler and better composable when slicing our big store into chunks. Furthermore, it comes with better TypeScript support. At the Pinia-Docs you will find a very detailed Guide for the Migration from Vuex Migrate Components Last but not least we decided to migrate all our components to the composition API with the &lt;script setup&gt; syntactical sugar . This is a step you can also omit or do in advance, but we recommend using this API since it&#8217;s also a bit more performant, and it reduces the boilerplate code you have to write. Finally: Migrate to Vue 3 You are now prepared to migrate to Vue 3, and you&#8217;ve done already a lot of things which made this step much easier and shorter. Now you can start the migration of Vue itself. Keep in mind, that for the actual migration you must migrate the unit tests too as the test utils for vue3 are slightly different. Migrate the source code Here we started by adding Vue 3 as well as the @vue/compat package as described in the Vue 3 Migration Build documentation . Also, we needed to update the VueRouter to version 4.x.x and adjust the configuration. As good step-by-step guides, I would recommend you again to read the following Blogposts: \"Vue.js: How to Migrate a large project from Vue 2 to Vue 3\" from Baptiste Jamin The official Vue 2 to Vue 3 Migration Guide . If you have already prepared some components in isolation to work with Vue 3 as we did: Of course you should replace the old ones and probably adjust the props or events if the API of your new components changed compared to the Vue 2 ones. After this step your whole app should work as before (fingers crossed). The migration of the components itself can be done one by one after the migration until everything is converted to Vue 3. Migrate to @vue/test-utils@v2 After you migrated everything, you need to update to @vue/test-utils@v2 . The migration should be straight-forward when following the migration guide . Nonetheless it can take quite a bit of time depending on the amount of unit tests you have. Post-Migration-Steps Remove Compatibility Package Once every component is migrated, make sure to remove the @vue/compat and it&#8217;s configuration as you don&#8217;t need it anymore. Make use of the Teleport feature Now that we are using Vue 3, we can use the \"Teleport\" feature. Think about components creating their DOM elements deeply in the DOM caused by the component hierarchy but where you would expect the elements to appear somewhere else close to the root. A good example is displaying a modal conditionally: &lt;body&gt; &lt;ComponentOne&gt; &lt;ComponentTwo&gt; &lt;ComponentThree&gt; &lt;MyModal v-if=\"myCondition\"&gt; &lt;/ComponentThree&gt; &lt;/ComponentTwo&gt; &lt;/ComponentOne&gt; &lt;/body&gt; In Vue 2, the modal would be rendered and appear inside the ComponentThree . Using teleport in MyModal can lift the element up to the body tag which makes more sense for common modal dialogs. Conclusion Migrating from Vue 2 to Vue 3 can be a huge thing and takes quite a bit of time. But good preparation and pre-migration will make the whole migration process much easier, more estimable and won&#8217;t block you for so long with releasing new features. Compared to writing the whole thing from scratch, we think this was well worth it. I hope this post gave you some inspiration of how you can face the migration of your project. Happy Migration ✌🏼 "
},

{
    "id": 2,
    "uri": "blog/2023/2023-05-05-loom-threading.html",
    "menu": "Blog",
    "title": "Projekt Loom ist da",
    "text": " Table of Contents Threading wie es sein soll: Projekt Loom ist da Virtualisierung hilft schon immer … und der Weg ins Schlamassel Threads sind die Grundlage der Nebenläufigkeit Asynchrone Programmierung als Notlösung Projekt Loom als Rettung VirtualThreads: benutzen ist (fast) einfacher als vermeiden Anpassungen im eigenen Code Angewohnheiten hinterfragen Synchron war nie schlecht Ausblick: Structured Concurrency Threading wie es sein soll: Projekt Loom ist da Es ist endlich so weit - das lang ersehnte Projekt Loom hat seinen Weg in das JDK gefunden! Seit über fünf Jahren haben wir uns danach gesehnt, all die Krücken wie NIO , asynchrone Programmierung , CompletableFutures und AsyncServlets hinter uns zu lassen und Java wieder so zu schreiben, wie wir es schon immer wollten. Virtualisierung hilft schon immer Auf jedem Rechner gibt es Ressourcen, die begrenzt sind. CPU-Zeit ist seit jeher eine knappe Ressource. Gleichzeitig müssen jedoch häufig viele kleine Aufgaben erledigt werden. Heutzutage verwenden wir meist API-Backends, die Anfragen über HTTP erhalten. Sie lesen Daten, transformieren sie und verändern sie gegebenenfalls. Anschließend wird die Antwort per Netzwerk-IO gesendet. Dabei die Ressourcen effizient zu nutzen, war von Anfang an eine Herausforderung und erforderte viel manuelle Arbeit. Zum Glück hatte Edsger W. Dijkstra bereits im Jahr 1965 die brillante Idee, den Zugriff auf wertvolle Ressourcen zu virtualisieren. So bekam das Berkeley Timesharing System die ersten Threads der Computer-Geschichte. Das Konzept war einfach: Threads sind kostengünstig und virtualisieren den Zugriff auf wertvolle Ressourcen. Figure 1. Threading wie die Urahnen - mit einer CPU Ein Scheduler sorgt dafür, dass blockierte Threads unterbrochen werden und andere Aufgaben ausgeführt werden können, bis die notwendigen Ressourcen verfügbar sind. Ein wahrhaft revolutionäres Konzept! Die Welt hat sich seit den ersten Threads des Berkeley Timesharing Systems weiterentwickelt. „Moderne“ Betriebssysteme wie AmigaOS haben das Konzept des Threading verbessert, indem sie es dem Betriebssystem erlauben, rechnende Prozesse zu unterbrechen und an anderer Stelle fortfahren zu lassen. Anders als bei User Threads in SunOS , wo der Code im Thread selbst anzeigt, wann er unterbrochen werden soll. … und der Weg ins Schlamassel Wir haben seitdem viel getan, um das Thread-Konzept kaputt zu bekommen. Wir nutzen gerade Netz-IO in modernen Anwendungen ganz intensiv. IO ist oft das, was diese Anwendungen am meisten machen. Und auf der anderen Seite ist die Hardware viel schneller als `65 . Wir haben so viele Requests zu verarbeiten und die Rechner sind schnell genug. Das geht. Wir können mal eben eine Million Sockets offenhalten und damit arbeiten. Nur: das Threading selbst kommt nur mit ein paar zehntausend Threads klar. Und deswegen sind inzwischen die Threads selbst die wertvolle Ressource. Und deswegen mussten wir anfangen, die Threads selbst zu teilen, zu poolen und sie wiederzuverwenden. Hierhin fällt der Aufstieg der Event-basierten IO-Bibliotheken . Netty fällt in diese Kategorie. Figure 2. IO-Thread und Worker-Thread bei der Arbeit IO und Worker Threads: ein speziell für IO-Operationen abgestellter Thread nimmt Daten entgegen. Dieser Thread wickelt sämtliche IO-Operationen ab. Damit entfällt auch die Notwendigkeit für Locking und Synchronisierung. Sobald Daten eingetroffen sind, werden sie in separaten Worker-Threads verarbeitet. Worker-Threads sollen selbst nie blockieren. Es wird dabei meistens nur ein Thread (manchmal einer pro CPU) mit IO beauftragt. Er arbeitet mit „non-blocking IO“ , erhält also Events, sobald eine IO-Operation abgeschlossen ist. Dadurch kann ein Thread alle offenen Sockets auf einmal bearbeiten. Sobald das IO abgeschlossen ist, wandert die Arbeit zu einem Worker-Thread weiter, der Berechnungen vornimmt. So lässt sich in unserem Beispiel bei drei gleichzeitig aktiven Requests die Thread-Zahl auf zwei reduzieren. Der Preis dafür ist, dass die Worker-Threads selbst Bescheid geben müssen, wenn sie fertig sind. Da ist dann das „alte“ kooperative Multitasking wieder. In der Praxis spielt das aber weniger eine Rolle, weil wir mehrere Worker-Threads benutzen, als Thread-Pool. Trotzdem – wir bezahlen gleich mehrere Preise dafür: Für jeden Request gibt es mindestens zwei Thread-Wechsel. Und die sind teuer. Sind Teile der Anwendung rechenintensiv, dann müssen wir selbst dafür sorgen, dass sie niemanden blockieren. Dann gibt es mehrere Thread-Pools. &#8230;&#8203; und wir brauchen ein kluges Threading-Konzept. Meistens heißt das, verschiedene Pools für Rechenlast, Netzwerk und File-IO einzuführen. Die IO-APIs sind alles andere als einfach zu bedienen. Und immer etwas anders. Netty für Netzwerk-IO. NIO für File-IO. RDBC für den Datenbankzugriff. Threads sind die Grundlage der Nebenläufigkeit Die Kernkonzepte von Java basieren auf Threads. Das gilt für den Sprachkern, die VM, fürs Debugging und das Profiling. IO-APIs waren synchron und sind in synchroner Form heute noch am übersichtlichsten zu benutzen. Das gesamte Exception-System ergibt nur innerhalb eines Threads wirklich Sinn. Speicherzugriffe innerhalb eines Threads sind geordnet und überschaubar. Wir könnten am übersichtlichsten alle Arbeit für einen Request in einem eigenen Thread erledigen. Wir könnten einfach einen Thread pro Request starten , synchrone APIs verwenden. Aber es geht nicht, weil einfach zu wenige Threads verfügbar sind. Asynchrone Programmierung als Notlösung Als Konsequenz opfern wir den Java-Sprachkern und verwenden reaktive Bibliotheken. Und müssen uns für Konstrukte wie Schleifen, If und Try-Catch komplett neue Konstrukte einfallen lassen. CompletableFuture .supplyAsync(info::getUrl, pool) .thenCompose(url -&gt; getBodyAsync( pool, HttpResponse.BodySubscribers.ofString(UTF_8))) .thenApply(info::findImage) .thenCompose(url -&gt; getBodyAsync( pool, HttpResponse.BodySubscribers.ofByteArray())) .thenApply(info::setImageData) .thenAccept(this::process) .exceptionally(t -&gt; { t.printStackTrace(); return null; }); Ohne auf den konkreten Inhalt dieses Handlers einzugehen, lässt sich die Auswirkung auf die Struktur der Programmiersprache erkennen: Das Programm wird nicht mehr in der üblichen Weise strukturiert, sondern über eine \"Fluent API\" erstellt und gestartet. Im Kern stellt das eine Monade dar, wie sie zum Beispiel aus Haskell bekannt ist. Dieses neue Sprachkonstrukt hat eine Reihe von Folgen, die interessant zu nutzen sind. Mit all den Problemen, die daraus resultieren, dass jetzt JVM, Werkzeuge, Sprache und Tools nicht mehr so recht zusammenpassen wollen: In Stack Traces steht oft kaum noch Hilfreiches . Mit dem Debugger durch ein reaktives Programm zu steppen ist eine Herausforderung. Und die Ursache für Lastprobleme zu finden, ist problematisch. Diesen Programmierstil verwenden wir definitiv nicht, weil er einfacher zu verstehen wäre. Oder weil er sonst irgendwie nützlicher zu handhaben wäre. Wir verwenden diesen Programmierstil, weil wir nicht anders skalieren können. Projekt Loom als Rettung Die Idee hinter Projekt Loom: Threads müssen wieder so billig werden wie damals. Es darf kein Problem sein, Millionen davon zu starten. Die JVM mappt dazu ihre eigene Art von Threads, die dort VirtualThreads heißen, auf Betriebssystem-Threads. Das ist ein M:N-Mapping. Also anders als damals zu Solaris-Zeiten, als „Green Threads“ eben nur auf einen einzigen OS-Thread abgebildet werden konnten. Aber ziemlich so, wie es in Erlang schon immer war. Und auch die Go-Fans lachten ja bereits über uns Java-Menschen. Die JVM kann das deswegen besser als das Betriebssystem, weil es zum einen mehr Wissen besitzt (zum Beispiel über Stack-Größen und das Speichermodell) und zum anderen, weil es Threads nicht jederzeit unterbrechen kann. Stattdessen wird nur dort unterbrochen, wo es blockierende Operationen gibt. Das sind hauptsächlich IO-Operationen, aber auch dort, wo wir in unseren Programmen manuell synchronisieren. Damit das funktioniert, gab es im Rahmen des Projekts Loom Anpassungen quer durch die JVM und die Basis-Bibliotheken. NIO wurde umgebaut. Das „alte“ IO wurde angepasst (und darf und soll damit ruhig wieder benutzt werden). Nur File-IO unter Windows ist noch ein Problem und dauert noch. VirtualThreads: benutzen ist (fast) einfacher als vermeiden Seit Java 19 können wir Threads sehr einfach als „virtual“ starten: var thread = Thread.startVirtualThread(() -&gt; { ... }); Das ist schon alles. Die JVM kümmert sich darum, dass diese VirtualThreads automatisch auf OS-Threads abgebildet werden. Normalerweise auf einen pro CPU-Kern. In diesem VirtualThread lassen sich nach Herzens Lust blockierende Aufrufe, Locks und Sleeps in synchroner Art platzieren. Wir sollen uns keine Gedanken mehr darüber machen, wie der Wettstreit um die Ressourcen läuft. Anpassungen im eigenen Code Einige Code-Konstrukte spielen nicht so gut mit VirtualThreads zusammen. Wir können sie ersetzen, damit der Code noch besser skaliert. Ganz weit vorne ist (jedenfalls derzeit) noch der „synchronized“-Block. Der hängt immer an einem OS-Thread, weil er mit Betriebssystemmitteln implementiert ist. Wir wollen ihn mit „ReentrantLock“ oder noch besser mit „StampedLock“ ersetzen. Der zweite Bereich sind JNI-Aufrufe. Die sind immer dann problematisch, wenn sie innerhalb von „synchronized“ passieren. Vor allem, wenn wir von nativem Code wieder nach Java callen, zum Beispiel bei Callbacks. Alles das muss uns aber nicht aufhalten. In den meisten Fällen machen ein paar wenige solche Stellen wenig aus. Viele Frameworks integrieren VirtualThreads bereits In Spring Boot Projekten werden wir bereits dahin geführt, dass wir Threading an zentraler Stelle implementieren. So wie Spring Boot es intern auch bereits macht. Wir können heute schon dafür sorgen, dass Spring Boot auf VirtualThreads setzt: @Configuration class ConfigureVirtualThreads { @Bean(TaskExecutionAutoConfiguration.APPLICATION_TASK_EXECUTOR_BEAN_NAME) public AsyncTaskExecutor asyncTaskExecutor() { return new TaskExecutorAdapter( Executors.newVirtualThreadPerTaskExecutor()); } @Bean public TomcatProtocolHandlerCustomizer&lt;?&gt; protocolHandlerVirtualThreadExecutorCustomizer() { return protocolHandler -&gt; { protocolHandler.setExecutor( Executors.newVirtualThreadPerTaskExecutor()); }; } } Mit der ersten Deklaration wird Spring konfiguriert. Der neue Task-Executor, den Spring an verschiedenen Stellen für asynchrone Aufrufe nutzt, erhält dafür jeweils einen neuen VirtualThread, statt wie vorher einen Thread-Pool. Die zweite Deklaration konfiguriert den eingebetteten Tomcat, mit dem Spring Boot die Web-Anfragen bearbeitet. Hier ist normalerweise ebenfalls ein Threadpool hinterlegt. Mit der Konfiguration fällt dieser Pool weg und es wird jedes Mal ein neuer VirtualThread zur Bearbeitung angelegt. Das als Configuration eingefügt und schon kommen Servlet-Requests bereits fertig als VirtualThread an. Spring Boot hat VirtualThreads auf dem Schirm, passt immer mal wieder etwas an und ist schon recht weit damit, VirtualThreads sehr effizient zu nutzen. Micronaut hat ebenfalls schon Support vorbereitet , der getestet werden kann. Und für Quarkus gibt es schon sehr weitreichenden Support . Und sogar in Wildfly 27 lässt sich VirtualThread-Support aktivieren. Angewohnheiten hinterfragen Mit Projekt Loom müssen wir fast nie neue Konzepte lernen. Stattdessen können wir alte Gewohnheiten ablegen: ThreadPools werden in den meisten Fällen keinen Mehrwert mehr bieten. Im Gegenteil fügen sie Overhead hinzu und verlangsamen den eigenen Code . Wo wir bisher Poolen, zum Beispiel um die Anzahl gleichzeitig durchgeführter Requests zu limitieren, können wir wieder (wie früher) Semaphoren beim Funktionsaufruf nutzen. Synchron war nie schlecht Und dann natürlich die Erkenntnis: für 99&#160;% aller Applikationen da draußen war asynchrone Programmierung nie nötig. Auch nicht ohne Projekt Loom. Die wenigsten haben mehr als 30.000 gleichzeitige Requests pro Service-Instanz. Moderne Hardware hat damit kein Problem, auch nicht mit 30k Betriebssystem-Threads. Und weil die Stack-Größe nur virtuellen Speicher angibt, haben wir auf 64-Bit-Systemen kein Problem damit. Ausblick: Structured Concurrency Bis mit Java 21 im Herbst 2023 das nächste LTS-Release aufschlägt, soll auch Structured Concurrency mit aufgenommen sein. Damit lassen sich dann die Stellen übersichtlich angehen, bei denen innerhalb einer Aufgabe Anfragen und Berechnungen parallel erfolgen sollen. @GetMapping(\"/trains\") fun listTrainsParallel(): TrainList&lt;TrainRepresentation&gt; { val list = StructuredTaskScope.ShutdownOnSuccess&lt;List&lt;Train&gt;&gt;().use { scope -&gt; scope.fork { serverA.listActiveSync() } scope.fork { serverB.listActiveSync() } scope.join().result().map { it.toListRepresentation() } } val count = StructuredTaskScope.ShutdownOnSuccess&lt;Int&gt;().use { scope -&gt; scope.fork { serverA.countActiveSync() } scope.fork { serverB.countActiveSync() } scope.joinUntil(Instant.now().plusSeconds(15)).result() } return TrainList(list, count) } Bei den beiden Abfragen können wir einfach (übrigens wieder als Monade) deklarieren, dass die dahinter liegenden Abfragen in separaten Threads erfolgen - im besten Fall in VirtualThreads. \"ShutdownOnSuccess\" sorgt dafür, dass das erste verfügbare Ergebnis gewinnt und alle anderen Threads beendet werden. Wir können einen Timeout mitgeben, um die Laufzeit - hier auf 15 Sekunden - zu begrenzen. Dabei ist wichtig: Es geht bei Structured Concurrency wirklich fast nur um die Lesbarkeit und Wartbarkeit. Schneller oder Ressourcen-sparender wird es dadurch nicht. Also: Es wird spannend im Java-Ökosystem. Mit Projekt Loom werden tatsächlich die Karten neu gemischt. Endlich können wir den Programmierstil wieder so aussuchen, wie er zu unseren Gehirnen passt. "
},

{
    "id": 3,
    "uri": "blog/2020/2020-12-15-digitaler-blindenhund.html",
    "menu": "Blog",
    "title": "Digitaler Blindenhund",
    "text": " Table of Contents Digitaler Blindenhund Video Digitaler Blindenhund Marcus hat den digitalen Blindenhund erdacht Eine Smartphone App, die es Menschen mit Seheinschränkung am Bahnhof ermöglicht, die Eingangstüren zu ihrem Zug selbstständig zu finden. Im Interview mit spricht Marcus über Barrierefreiheit im Allgemeinen und bei der Darstellung von digitalen Inhalten. Und wir sprechen über die alltäglichen Herausforderungen an Bahnhöfen, zum Beispiel das Finden des richtigen Bahnsteigs. Der digitale Blindenhund ist ein Beispiel, wie für solche Fälle eine Hilfe aussehen kann. Im ersten Schritt wurde sich auf die Erkennung von Türen fokussiert, da dieses Problem für Blinde eine besondere Herausforderung darstellt. Marcus erläutert uns dabei die vielfältigen Herausforderungen und Ansätze die ausprobiert wurden, bis sie zu einer technisch sinnvollen Lösung auf Basis eines neuronalen Netzes gekommen sind. Video "
},

{
    "id": 4,
    "uri": "blog/2020/2020-05-19-5vue-js-vs-angular-was-ist-besser.html",
    "menu": "Blog",
    "title": "Vue.js vs. Angular",
    "text": " Table of Contents Vue.js vs. Angular: Was ist besser? Video Vue.js vs. Angular: Was ist besser? Heute zu Gast bei #000000 #c0ffee – Der Tech-Talk der DB Systel. Von Techies für Techies: Danny Koppenhagen Danny ist Frontend-Entwickler mit den Schwerpunkten Angular und Vue.js und einer der Autoren des Buches „Angular — Grundlagen, fortgeschrittene Themen und Best Practices“. Im dx.house Berlin berät er außerdem Kunden und Teams in den Themen User Experience von Enterprise-Lösungen. Er engagiert sich in der Web Community der DB Systel und ist Mitglied im Themen Team Web der Architekturgilde. Dort erarbeitet er Architektur-Standards für alle Themen Web. Im Interview spricht er über seine Erfahrungen mit Vue.js und Angular. Er geht darauf ein, welches Framework sich für welche Anwendungszwecke eignet. So bietet Vue.js hauptsächlich Vorteile, wenn es um die Integration in bestehende Anwendungen handelt und das Team gerne JavaScript einsetzt. Angular ist im Enterprise-Umfeld für neue Anwendungen interessant, da es auf TypeScript aufsetzt, ein umfangreiches Ökosystem mitbringt und zum Beispiel Migrationsguides und Templating-Fähigkeiten über sogenannte Schematics mitbringt. Außerdem erläutert Danny wie der aktuelle Stand der Technik für Progressive Webapps (PWA) ist. Hier kommt es darauf an, ob alle benötigten Features des Betriebssystems angesprochen werden können. Falls nicht, sollte in Erwägung gezogen werden eine native App zu entwickeln. Im dritten Teil sprechen wir über die Anbindung von APIs. Um die Orchestrierung von APIs zu vereinfachen, kann hier das Architekturmuster Backend For Frontends zum Einsatz kommen. Das vereinfacht den Zugriff aus der Anwendung, da die Anbindung der APIs nicht einzeln im Frontend implementiert werden muss. Erfahre mehr zum Thema:    • #000000 #c0ffee Tech-Talk   Video "
},

{
    "id": 5,
    "uri": "blog/2019/2019-09-13-Spock-und-AsciiDoc.html",
    "menu": "Blog",
    "title": "Spock und AsciiDoc",
    "text": " Table of Contents Spock und AsciiDoc - vom Test zur Spezifikation und zurück Slides und Video Spock und AsciiDoc - vom Test zur Spezifikation und zurück Spock ist ein Testframework für Webanwendungen, mit dem man unter anderem den Behavior Driven Development Ansatz, kurz BDD, verfolgen kann. Der Product Owner beschreibt das Verhalten einer Applikation und der Entwickler überprüft es über einen automatischen Test. Dem Entwickler reicht die Ausgabe \"PASSED\" oder \"FAILED\", denn er kennt ja den Code seiner Tests. Wäre es nicht cool, wenn auch der Product Owner ein verständliches Dokument bekäme? Kein Problem! Wir generieren über ein Template einfach einen Test-Report in AsciiDoc und fügen weitere erklärende Texte hinzu um eine les- und ausführbare Spezifikation zu erhalten. Screenshots aller wichtigen Schritte bereichern die Spezifikation weiter. Sollte aber die Spezifikation nicht am Anfang stehen? Und warum Spezifikation, wenn wir agil sein wollen? Richtig! Stellen wir also eine iterative Feature-Beschreibung an den Anfang und verfeinern diese mit automatischen Tests um am Ende eine gut lesbare und verifizierbare Spezifikation des Verhaltens unseres Systems zu erhalten! Die Vorteile liegen auf der Hand – die Vorgehensweise verbessert die Kommunikation zwischen Product Owner und Entwicklern und am Ende bekommen wir ein Dokument welches Ihre wertvolle Software korrekt und überprüfbar beschreibt. Slides und Video "
},

{
    "id": 6,
    "uri": "blog/index.html",
    "menu": "Blog",
    "title": "Übersicht",
    "text": " Table of Contents Übersicht Übersicht Willkommen auf dem Tech-Blog der DB-Systel. "
},

{
    "id": 7,
    "uri": "blog/profiles/Bertram-Fey.html",
    "menu": "Autoren",
    "title": "Bertram Fey",
    "text": " Table of Contents Bertram Fey Bertram Fey span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 8,
    "uri": "blog/profiles/Ralf-D.-Mueller.html",
    "menu": "Autoren",
    "title": "Ralf D. Müller",
    "text": " Table of Contents Ralf D. Müller Ralf D. Müller span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Ralf is a Software Engineering Advocate at DB Systel GmbH during the day and after sunset he loves everything with bits and bytes. The last few years of his career, he focused on the documentation of software systems with arc42 and the Docs-as-Code approach. You can follow him on mastodon rdmueller@mastodontech.de . "
},

{
    "id": 9,
    "uri": "blog/profiles/Marcus-Suemnick.html",
    "menu": "Autoren",
    "title": "Marcus Sümnick",
    "text": " Table of Contents Marcus Sümnick Marcus Sümnick span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } "
},

{
    "id": 10,
    "uri": "blog/profiles/Danny-Koppenhagen.html",
    "menu": "Autoren",
    "title": "Danny Koppenhagen",
    "text": " Table of Contents Danny Koppenhagen Links Danny Koppenhagen span.profile img { border: 5px solid #288ABF; border-radius: 10px; max-width: 100px; } Danny is an experienced frontend architect at DB Systel GmbH which is the digital partner of the biggest German railway company Deutsche Bahn . He develops and architects’ enterprise web applications within a DevOps team facing the micro mobility market. Furthermore, he is an open-source enthusiast and one of the authors of the popular German-language Angular book . Links Mastodon Profile X (formerly known as Twitter) Profile GitHub Profile Personal Website "
},

{
    "id": 11,
    "uri": "lunrjsindex.html",
    "menu": "null",
    "title": "null",
    "text": " will be replaced by the index "
},

];
